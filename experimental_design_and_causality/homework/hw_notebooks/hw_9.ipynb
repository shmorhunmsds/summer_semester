{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43aa22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9fd127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(A=1, B=1, C=10, D=1000):\n",
    "  W = np.random.normal(0,1,D)\n",
    "  X = W+np.random.normal(0,B,D)\n",
    "  Y = A*X-W+np.random.normal(0,C,D)\n",
    "  return Y, X, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054ae430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "X",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "W",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2b5a9900-28bd-4d47-b1f4-a363d7274c0c",
       "rows": [
        [
         "0",
         "0.797687854711594",
         "5.06230997993132",
         "0.758725117101272"
        ],
        [
         "1",
         "-1.037010172933959",
         "-17.02822401102501",
         "-2.1270960133984493"
        ],
        [
         "2",
         "0.9796305177663458",
         "-6.554048285801828",
         "0.3764452121113852"
        ],
        [
         "3",
         "-1.7935278901093803",
         "4.465854972323411",
         "-0.8911744570744754"
        ],
        [
         "4",
         "-0.2395513609542722",
         "0.3169797815739481",
         "0.29963552305084584"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.797688</td>\n",
       "      <td>5.062310</td>\n",
       "      <td>0.758725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.037010</td>\n",
       "      <td>-17.028224</td>\n",
       "      <td>-2.127096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979631</td>\n",
       "      <td>-6.554048</td>\n",
       "      <td>0.376445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.793528</td>\n",
       "      <td>4.465855</td>\n",
       "      <td>-0.891174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.239551</td>\n",
       "      <td>0.316980</td>\n",
       "      <td>0.299636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X          Y         W\n",
       "0  0.797688   5.062310  0.758725\n",
       "1 -1.037010 -17.028224 -2.127096\n",
       "2  0.979631  -6.554048  0.376445\n",
       "3 -1.793528   4.465855 -0.891174\n",
       "4 -0.239551   0.316980  0.299636"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the sim\n",
    "Y, X, W = simulate(A=1, B=1, C=10, D=1000)\n",
    "\n",
    "# build a DataFrame, calling W “Z”\n",
    "df = pd.DataFrame({\n",
    "    'X': X,\n",
    "    'Y': Y,\n",
    "    'W': W\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf04e737",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Which of the following is closest to the probability of detecting a nonzero effect of $X$ on $Y$ (the t-value of $X$ is greater in absolute value than about 1.96) given A = 1, B = 1, C = 10, D = 1000? Include W in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the sim\n",
    "Y, X, W = simulate(A=1, B=1, C=10, D=1000)\n",
    "\n",
    "# build a DataFrame, calling W “Z”\n",
    "df = pd.DataFrame({\n",
    "    'X': X,\n",
    "    'Y': Y,\n",
    "    'W': W\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59aa2984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Jul 2025</td> <th>  Prob (F-statistic):</th>  <td>0.00141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:51:05</td>     <th>  Log-Likelihood:    </th> <td> -3731.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   7470.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   997</td>      <th>  BIC:               </th> <td>   7484.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.5483</td> <td>    0.320</td> <td>   -1.712</td> <td> 0.087</td> <td>   -1.177</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>         <td>    1.1371</td> <td>    0.316</td> <td>    3.593</td> <td> 0.000</td> <td>    0.516</td> <td>    1.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>W</th>         <td>   -0.9515</td> <td>    0.448</td> <td>   -2.122</td> <td> 0.034</td> <td>   -1.832</td> <td>   -0.071</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.123</td> <th>  Durbin-Watson:     </th> <td>   1.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.940</td> <th>  Jarque-Bera (JB):  </th> <td>   0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.013</td> <th>  Prob(JB):          </th> <td>   0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.030</td> <th>  Cond. No.          </th> <td>    2.59</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        Y         & \\textbf{  R-squared:         } &     0.013   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.011   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     6.605   \\\\\n",
       "\\textbf{Date:}             & Fri, 18 Jul 2025 & \\textbf{  Prob (F-statistic):} &  0.00141    \\\\\n",
       "\\textbf{Time:}             &     20:51:05     & \\textbf{  Log-Likelihood:    } &   -3731.9   \\\\\n",
       "\\textbf{No. Observations:} &        1000      & \\textbf{  AIC:               } &     7470.   \\\\\n",
       "\\textbf{Df Residuals:}     &         997      & \\textbf{  BIC:               } &     7484.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      -0.5483  &        0.320     &    -1.712  &         0.087        &       -1.177    &        0.080     \\\\\n",
       "\\textbf{X}         &       1.1371  &        0.316     &     3.593  &         0.000        &        0.516    &        1.758     \\\\\n",
       "\\textbf{W}         &      -0.9515  &        0.448     &    -2.122  &         0.034        &       -1.832    &       -0.071     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.123 & \\textbf{  Durbin-Watson:     } &    1.991  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.940 & \\textbf{  Jarque-Bera (JB):  } &    0.066  \\\\\n",
       "\\textbf{Skew:}          & -0.013 & \\textbf{  Prob(JB):          } &    0.968  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.030 & \\textbf{  Cond. No.          } &     2.59  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.013\n",
       "Model:                            OLS   Adj. R-squared:                  0.011\n",
       "Method:                 Least Squares   F-statistic:                     6.605\n",
       "Date:                Fri, 18 Jul 2025   Prob (F-statistic):            0.00141\n",
       "Time:                        20:51:05   Log-Likelihood:                -3731.9\n",
       "No. Observations:                1000   AIC:                             7470.\n",
       "Df Residuals:                     997   BIC:                             7484.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.5483      0.320     -1.712      0.087      -1.177       0.080\n",
       "X              1.1371      0.316      3.593      0.000       0.516       1.758\n",
       "W             -0.9515      0.448     -2.122      0.034      -1.832      -0.071\n",
       "==============================================================================\n",
       "Omnibus:                        0.123   Durbin-Watson:                   1.991\n",
       "Prob(Omnibus):                  0.940   Jarque-Bera (JB):                0.066\n",
       "Skew:                          -0.013   Prob(JB):                        0.968\n",
       "Kurtosis:                       3.030   Cond. No.                         2.59\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS.from_formula('Y ~ X + W', data=df)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e3a221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical probability of detecting X (power): 0.883\n"
     ]
    }
   ],
   "source": [
    "def estimate_power(nsim=1000, alpha=0.05):\n",
    "    \"\"\"Estimate the probability of |t| > 1.96 for X across nsim simulations.\"\"\"\n",
    "    detections = []\n",
    "    for _ in range(nsim):\n",
    "        Y, X, W = simulate(A=1, B=1, C=10, D=1000)\n",
    "        df = pd.DataFrame({'X': X, 'W': W, 'Y': Y})\n",
    "        \n",
    "        # fit Y ~ X + W\n",
    "        model = sm.OLS(df['Y'], sm.add_constant(df[['X', 'W']])).fit()\n",
    "        t_x = model.tvalues['X']\n",
    "        \n",
    "        # record whether |t| exceeds the 1.96 threshold\n",
    "        detections.append(abs(t_x) > 1.96)\n",
    "        \n",
    "    return np.mean(detections)\n",
    "\n",
    "# Run the power simulation\n",
    "power_estimate = estimate_power(nsim=2000)\n",
    "print(f\"Empirical probability of detecting X (power): {power_estimate:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fa148",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Which of the following is closest to the skew of the estimate in that case? (You can compute this using scipy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1a71af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical skew of the X coefficient estimates: 0.049\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Re‑use your simulate function\n",
    "def simulate(A=1, B=1, C=10, D=1000):\n",
    "    W = np.random.normal(0, 1, D)\n",
    "    X = W + np.random.normal(0, B, D)\n",
    "    Y = A * X - W + np.random.normal(0, C, D)\n",
    "    return Y, X, W\n",
    "\n",
    "def estimate_skew(nsim=2000, alpha=0.05):\n",
    "    \"\"\"Estimate the skewness of the distribution of the X coefficient estimates.\"\"\"\n",
    "    coefs = []\n",
    "    for _ in range(nsim):\n",
    "        Y, X, W = simulate(A=1, B=1, C=10, D=1000)\n",
    "        df = pd.DataFrame({'X': X, 'W': W, 'Y': Y})\n",
    "        \n",
    "        # fit Y ~ X + W\n",
    "        model = sm.OLS(df['Y'], sm.add_constant(df[['X', 'W']])).fit()\n",
    "        coefs.append(model.params['X'])\n",
    "        \n",
    "    return skew(coefs)\n",
    "\n",
    "# Run the skewness simulation\n",
    "skew_estimate = estimate_skew(nsim=2000)\n",
    "print(f\"Empirical skew of the X coefficient estimates: {skew_estimate:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7b6c1",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "With A = 1, C = 10, D = 1,000, what value of B is needed to detect that the Data Generating Process (DGP) has a nonzero coefficient for X about 50% of the time? (Choose the closest value.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "389dbd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.0966\n",
      "0.6 0.4758\n",
      "1.8 0.9998\n",
      "5.4 1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "def power_for_B(B, nsim=1000, alpha=0.05):\n",
    "    tcrit = t.ppf(1 - alpha/2, df=1000-3)   # approx df=D–#params\n",
    "    detects = []\n",
    "    for _ in range(nsim):\n",
    "        Y, X, W = simulate(A=1, B=B, C=10, D=1000)\n",
    "        df = pd.DataFrame({'Y':Y,'X':X,'W':W})\n",
    "        m = sm.OLS(df.Y, sm.add_constant(df[['X','W']])).fit()\n",
    "        detects.append(abs(m.tvalues['X']) > tcrit)\n",
    "    return np.mean(detects)\n",
    "\n",
    "# sweep over Bs to find ~50%:\n",
    "for B in [0.2, 0.6, 1.8, 5.4]:\n",
    "    print(B, power_for_B(B, nsim=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd64e8d",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "With B = 1, C = 10, D = 100 (note the different value of D), what value of A is needed to detect that the DGP has a nonzero coefficient for X about 50% of the time? (Choose the closest value.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d8977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.0805\n",
      "1.0 0.1726\n",
      "2.0 0.5018\n",
      "4.0 0.9719\n"
     ]
    }
   ],
   "source": [
    "def power_for_A(A, nsim=1000, alpha=0.05):\n",
    "    tcrit = t.ppf(1 - alpha/2, df=1000-3)   # approx df=D–#params\n",
    "    detects = []\n",
    "    for _ in range(nsim):\n",
    "        Y, X, W = simulate(A=A, B=1, C=10, D=100)\n",
    "        df = pd.DataFrame({'Y':Y,'X':X,'W':W})\n",
    "        m = sm.OLS(df.Y, sm.add_constant(df[['X','W']])).fit()\n",
    "        detects.append(abs(m.tvalues['X']) > tcrit)\n",
    "    return np.mean(detects)\n",
    "\n",
    "# sweep over Bs to find ~50%:\n",
    "for A in [0.5, 1.0, 2.0, 4.0]:\n",
    "    print(A, power_for_A(A, nsim=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7c0f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = 0.50 → power ≈ 0.082\n",
      "A = 1.00 → power ≈ 0.165\n",
      "A = 2.00 → power ≈ 0.493\n",
      "A = 4.00 → power ≈ 0.972\n"
     ]
    }
   ],
   "source": [
    "def simulate(A=1, B=1, C=10, D=100):\n",
    "    W = np.random.normal(0, 1, D)\n",
    "    X = W + np.random.normal(0, B, D)\n",
    "    Y = A * X - W + np.random.normal(0, C, D)\n",
    "    return Y, X, W\n",
    "\n",
    "def power_for_A(A, nsim=2000, alpha=0.05, D=100):\n",
    "    df_resid = D - 3                      # 100 obs − 3 params\n",
    "    tcrit    = t.ppf(1 - alpha/2, df=df_resid)\n",
    "    detects  = []\n",
    "    \n",
    "    for _ in range(nsim):\n",
    "        Y, X, W = simulate(A=A, B=1, C=10, D=D)\n",
    "        df = pd.DataFrame({'Y': Y, 'X': X, 'W': W})\n",
    "        m  = sm.OLS(df.Y, sm.add_constant(df[['X','W']])).fit()\n",
    "        detects.append(abs(m.tvalues['X']) > tcrit)\n",
    "    \n",
    "    return np.mean(detects)\n",
    "\n",
    "# Try a grid of A’s and see which gives ~50% power\n",
    "for A in [0.5, 1.0, 2.0, 4.0]:\n",
    "    p = power_for_A(A, nsim=5000, alpha=0.05, D=100)\n",
    "    print(f\"A = {A:4.2f} → power ≈ {p:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852bf1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
