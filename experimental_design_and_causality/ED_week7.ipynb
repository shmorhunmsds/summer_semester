{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa7e8d7",
   "metadata": {},
   "source": [
    "# Week 7 Overview\n",
    "This week, we review the fundamentals of simple linear regression, including how to calculate the slope and interpret the intercept. We explore the differences between error terms and residuals and discuss the significance of confounders in regression analysis. Additionally, we examine key statistical measures used to assess the accuracy of regression models. There is a lot of content and reading this week. We will focus primarily on the material through Lesson 2.3.\n",
    "\n",
    "## Learning Objectives\n",
    "At the end of this week, you will be able to: \n",
    "- Explain the difference between error terms and residuals in regression \n",
    "- Identify potential confounders in a regression model \n",
    "- Explain the common assumptions for a regression model \n",
    "- Interpret statistical measures to assess regression model accuracy \n",
    "- Compute slope in simple regression and distinguish between error terms and residuals for accurate modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fd392",
   "metadata": {},
   "source": [
    "## Topic Overview: Regression Concepts and Error Terms \n",
    "In this topic, we cover how the slope in a simple regression situation is computed, with the estimate of the slope being the covariance of $X$ and $Y$ divided by the variance of $X$. We also discuss the distinction between error terms and residuals, the relationship between the true regression model and noise ($\\varepsilon$), and the importance of ensuring that the error term is uncorrelated with $X$ for an accurate model. \n",
    "\n",
    "### Learning Objectives\n",
    "- Explain the difference between error terms and residuals in regression \n",
    "- Identify potential confounders in a regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925cd28",
   "metadata": {},
   "source": [
    "## Understanding Error in Regression\n",
    "\n",
    "### How We Compute the Slope in a Simple Regression Situation \n",
    "\n",
    "With one predictor (X), the estimate of the slope is the covariance of $X$ and $Y$: \n",
    "$$ E_{sample} ((X - \\langle X \\rangle )) \\cdot  (X - ( \\langle X \\rangle )) $$  \n",
    "\n",
    "Divided by the variance of $X$. \n",
    "\n",
    "$E_{sample} ((X - \\langle X \\rangle))^2 $\n",
    "\n",
    "### Error Terms\n",
    "If we subtract the predicted value $(\\hat{Y})$ from the actual outcome $Y$, we get the **residual**. \n",
    "\n",
    "There is a difference between the **error** and the **residual**. In regression, the \"true\" relationships between $X$ and $Y$ is:\n",
    "\n",
    "$$ Y \\; =  \\; \\beta_0 + \\beta_1 X + \\varepsilon $$ \n",
    "\n",
    "Where:\n",
    "\n",
    "$\\varepsilon$ is some noise; it is a random variable. \n",
    "\n",
    "We could write $\\varepsilon (X = x)$, meaning that epsilon can be conditioned on a particular value of $X$. If there is anothe variable $Z$, then $\\varepsilon(Z = z)$ is also valid. \n",
    "\n",
    "That is, perhaps at $X = 0, \\varepsilon (X = 0)$ is a random normal distribution with mean 0 and a standard deviation 1, but at $X = 1, \\varepsilon (X = 1)$ is a random normal distribution with mean 0 and standard deviation 2. \n",
    "\n",
    "On the other hand, $\\varepsilon(Z = 0)$ may be something totally different. \n",
    "\n",
    "We do, however, require that the mean of $\\varepsilon(X = x)$ is 0 no matter the value of $X$. Otherwise, we'd say that X is correlated iwth the error term. \n",
    "\n",
    "if we predict $Y = \\beta_0 + \\beta_1 X$, then $\\varepsilon$ is the error term, which is similar to the residual. However, they are not always the same. For example, if we get the $\\beta_1$ coefficient wrong, like $Y = \\beta_0 + \\beta_1 \\prime X$, then the residual is is $(\\beta_1 - \\beta_1 \\prime) X + \\varepsilon$\n",
    "\n",
    "Since $\\varepsilon$ is a random variable, and epsilon is part of $Y$, it follows that $Y$ is a random variable too - it does not uniquely depend on $X$. \n",
    "\n",
    "We could think of the error as \"random\", but presumably, any error depends on something, even if it depends on a butterfly flapping its wings. (There is an idea in chaos theory that the weather can change when a butterfly flaps its wings.) \n",
    "\n",
    "So, perhaps $\\varepsilon (X = x)$ is a random variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77767737",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
